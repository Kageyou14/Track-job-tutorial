import streamlit as st
import pandas as pd
from get_paper_info import get_paper_info_from_crossref
import db_utils

st.set_page_config(layout="wide") 

db_utils.init_db()
# #ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®ä½œæˆ
# if "papers" not in st.session_state:
#     st.session_state.papers = pd.DataFrame(columns=["title", "authors", "journal", "year", "doi", "url"])

# st.sidebar.title("æ“ä½œãƒ‘ãƒãƒ«")
#ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›æ¬„
st.sidebar.header("è«–æ–‡æ¤œç´¢")
# 1. æ¤œç´¢ãƒãƒ¼ã‚’ãƒ¡ã‚¤ãƒ³ç”»é¢ã«è¨­ç½®
search_query = st.sidebar.text_input("ç™»éŒ²è«–æ–‡ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã§æ¤œç´¢", placeholder="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›â€¦")


st.sidebar.header("è«–æ–‡ã®è¿½åŠ ")
with st.sidebar.form(key="add_form"):
    doi = st.text_input("DOIã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    submitted = st.form_submit_button("è¿½åŠ ")
    if submitted:
            if doi:
                if db_utils.check_doi_exists(doi):
                    st.warning("ã“ã®DOIã¯æ—¢ã«è¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚")
                else:
                    data = get_paper_info_from_crossref(doi)
                    if data:
                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ² 
                        paper_info = {
                            "title": data["title"],
                            "authors": data["authors"],
                            "journal": data["journal"],
                            "year": data["year"],
                            "volume": data["volume"],  
                            "issue": data["issue"],   
                            "pages": data["pages"],    
                            "doi": data["doi"],
                            "url": data["url"],
                            "memo": ""
                        }
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«è¿½åŠ  
                        db_utils.add_paper(paper_info)
                    
                        st.toast(f"è«–æ–‡ã€Œ{data['title']}ã€ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼", icon="âœ…")
                    else:
                        st.error("æ­£ã—ã„DOIã§ã¯ãªã„ã‹ã€æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.warning("DOIã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

st.title("è«–æ–‡ç®¡ç†ãƒ„ãƒ¼ãƒ«")
st.subheader("ç™»éŒ²æ¸ˆã¿è«–æ–‡ä¸€è¦§")
all_papers = db_utils.get_all_papers()
if search_query:
    # .str.contains() ã‚’ä½¿ã„ã€ã‚¿ã‚¤ãƒˆãƒ«åˆ—ã«æ¤œç´¢èªãŒå«ã¾ã‚Œã‚‹è¡Œã ã‘ã‚’æŠ½å‡ºã™ã‚‹
    filtered_papers = all_papers[all_papers['title'].str.contains(search_query, case=False, na=False)]
else:
    # æ¤œç´¢ãƒãƒ¼ãŒç©ºã®å ´åˆã¯ã€ã™ã¹ã¦ã®è«–æ–‡ã‚’è¡¨ç¤ºã™ã‚‹
    filtered_papers = all_papers

st.divider()

# 1. ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’æ‰‹å‹•ã§ä½œæˆ
col_header1, col_header2, col_header3, col_header4 = st.columns([4, 3, 1, 1])
with col_header1:
    st.markdown("**ã‚¿ã‚¤ãƒˆãƒ«**")
with col_header2:
    st.markdown("**è‘—è€…**")
with col_header3:
    st.markdown("**ç™ºè¡Œå¹´**")
with col_header4:
    st.markdown("**è«–æ–‡URL**")

st.divider()

# 2. forãƒ«ãƒ¼ãƒ—ã§å„è«–æ–‡ã®è¡Œã‚’æç”»
if filtered_papers.empty:
    st.info("è¡¨ç¤ºã™ã‚‹è«–æ–‡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
else:
    for index, paper in filtered_papers.iterrows():
        col1, col2, col3, col4 = st.columns([4, 3, 1, 1])
        
        # ã‚¿ã‚¤ãƒˆãƒ«è‡ªä½“ã‚’è©³ç´°ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã«ã™ã‚‹
        with col1:
            # Markdownã®ãƒªãƒ³ã‚¯æ§‹æ–‡: [è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆ](URL)
            st.markdown(
                f" [{paper['title']}](details?id={int(paper['id'])})",
                unsafe_allow_html=True # ãƒªãƒ³ã‚¯ã‚’æœ‰åŠ¹ã«ã™ã‚‹ãŸã‚ã«å¿…è¦
            )

        
        # ãã®ä»–ã®æƒ…å ±ã‚’è¡¨ç¤º
        with col2:
            st.write(paper["authors"])
        with col3:
            st.write(paper["year"])
        with col4:
            if paper["url"]:
                st.markdown(
                    f'<a href="{paper["url"]}" target="_blank">ğŸ”— Link</a>', 
                    unsafe_allow_html=True
                )
        
        st.divider()
